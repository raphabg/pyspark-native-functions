{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "4aeacaa4-901d-441f-a8e8-4c1bae28c774"
            },
            "source": [
                "## Fuzzy Match POC with Apache Spark\n",
                "The objective of this project is to test the execution of native spark functions to perform string similarity analysis, with variated similarity analysis algorithms\n",
                "\n",
                "### Approaches\n",
                "\n",
                "- 2nd Approach: Use of Term Frequency, Inverse Document Frequency (TF-IDF) and only then applying native Scala Spark SQL fuzzy match algorithms\n",
                "\n",
                "References:\n",
                "- [Josh Taylor: Fuzzy matching at scale](https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536#:~:text=The%20problem%20with%20Fuzzy%20Matching%20on%20large%20data&text=In%20computer%20science%2C%20this%20is,that%20works%20in%20quadratic%20time.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "azdata_cell_guid": "a7291e39-9e81-4859-868e-713730d26357",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd\n",
                "import names\n",
                "from sklearn.neighbors import NearestNeighbors\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "277c556d-9166-4088-8151-b357c4b6c11b"
            },
            "source": [
                "### Prepare datasets\n",
                "`targets` is the name list that will be looked up inside `comparison`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "azdata_cell_guid": "ed14ad64-b015-4c66-b253-68551dcf4cba",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "15\n",
                        "34\n",
                        "CrossJoined dataset size: 510\n"
                    ]
                }
            ],
            "source": [
                "targets = []\n",
                "comparison = []\n",
                "\n",
                "targets.append({'SimilarityWith': 'HP PARTICIPACOES S/A'})\n",
                "targets.append({'SimilarityWith': 'SAMSUMG'})  \n",
                "targets.append({'SimilarityWith': 'JOAO PEDRO PAULO'})  \n",
                "targets.append({'SimilarityWith': 'PEDRO CHRISTIAN DA SILVA JR.'})\n",
                "targets.append({'SimilarityWith': 'LUIS CARLOS JR'})\n",
                "targets.append({'SimilarityWith': 'JOAO PEDRO FREDERICH HESRV'})\n",
                "targets.append({'SimilarityWith': 'CAMARGO CORREA SA'})\n",
                "targets.append({'SimilarityWith': 'SANTOS BRASIL TERMINAL PORTUARIO DE EXPORTACAO'})\n",
                "targets.append({'SimilarityWith': 'CONCAIS TERMINAL PORTUARIO'})\n",
                "targets.append({'SimilarityWith': 'JUNIOR RONALD FLINDSMAN'})\n",
                "targets.append({'SimilarityWith': 'COCA COLA LTDA'})\n",
                "targets.append({'SimilarityWith': 'BRASTEMP PRODUTOS TECNOLOGICOS LTDA'})\n",
                "targets.append({'SimilarityWith': 'MINERVA EXPORTACAO DE CARNES'})\n",
                "targets.append({'SimilarityWith': 'CENTRO DE CONVENCOES JESUS LUZ'})\n",
                "targets.append({'SimilarityWith': 'JUAN MERCADO DA SILVA'})\n",
                "\n",
                "#-----------------------------------NOME 2--------------------------------------\n",
                "comparison.append({'Name': 'HAP PARCTICIPACOES S/A'})\n",
                "comparison.append({'Name': 'HPPY PARTY S/A'})\n",
                "comparison.append({'Name': 'HIPPIES PATTERN S/A'})\n",
                "comparison.append({'Name': 'SAMSUNG'}) \n",
                "comparison.append({'Name': 'JOHN PEDRO PAULO'}) \n",
                "comparison.append({'Name': 'JOAO ROBERTO DA SILVA'})\n",
                "comparison.append({'Name': 'JOANA PEDROSO FERRAZ'})\n",
                "comparison.append({'Name': 'PEDRO SILVA JUNIOR'})\n",
                "comparison.append({'Name': 'PERSIO FERREIRA JUNIOR'})\n",
                "comparison.append({'Name': 'LUIS CARLOS OLIVERIA JUNIOR'})\n",
                "comparison.append({'Name': 'LUISA CAROLINA BORGES'})\n",
                "comparison.append({'Name': 'JOAO FRED HESRV'})\n",
                "comparison.append({'Name': 'FREDERICO HENRIQUE'})\n",
                "comparison.append({'Name': 'FREDERICO PEDROZO DE MORAES'})\n",
                "comparison.append({'Name': 'C CORREA EMPREENDIMENTOS SA'})\n",
                "comparison.append({'Name': 'CENTRO CORREAS E ACESSORIOS'})\n",
                "comparison.append({'Name': 'CISNEI CISCORREA EMPREITEIRA SA'})\n",
                "comparison.append({'Name': 'TRASNPETRO EXPORTACAO'})\n",
                "comparison.append({'Name': 'CONCAIS TERMINAL'})\n",
                "comparison.append({'Name': 'RONALD FLINDSMAN'})\n",
                "comparison.append({'Name': 'RONALDO FLETCHER ARMANDO'})\n",
                "comparison.append({'Name': 'COCA COLA LTDA'})\n",
                "comparison.append({'Name': 'COCADA DA MARIA LTDA'})\n",
                "comparison.append({'Name': 'BRASTEMP TECH LTDA'})\n",
                "comparison.append({'Name': 'BRASIL TECNOLOGIA LTDA'})\n",
                "comparison.append({'Name': 'MINERVA COMEX SERVICOS ALIMENTICIOS'})\n",
                "comparison.append({'Name': 'MINERIO EXPLORACAO E CAVAGEM'})\n",
                "comparison.append({'Name': 'MINAS GERAIS EXP'})\n",
                "comparison.append({'Name': 'CENTRO DE CONVENCOES SAO PAULO EXPOCENTER'})\n",
                "comparison.append({'Name': 'CELTIC CONNECTION SAO PAULO'})\n",
                "comparison.append({'Name': 'MERCADO DA SILVIA'})\n",
                "comparison.append({'Name': 'JOANA DA SILVA'})\n",
                "comparison.append({'Name': 'Raphael Almeida Balogo'})\n",
                "comparison.append({'Name': 'XY'})\n",
                "\n",
                "print(len(targets))\n",
                "print(len(comparison))\n",
                "\n",
                "print(f\"CrossJoined dataset size: {len(targets) * len(comparison)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "04f98435-9898-4c98-ac72-b0a8b56d22b2"
            },
            "source": [
                "<hr>\n",
                "\n",
                "### Term Frequency, Inverse Document Frequency (TF-IDF) Approach "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "42e58380-fcb7-495c-b08e-75654ec29bde"
            },
            "source": [
                "\n",
                "Function that generates list of 3 char length ngrams from full string "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "azdata_cell_guid": "b3d1418c-376a-453e-bedf-6ab1335003ab",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "def ngrams(string, n=3):\n",
                "    ngs = zip(*[string[i:] for i in range(n)])\n",
                "    return [''.join(n) for n in ngs]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "azdata_cell_guid": "342ba2e9-9954-49fe-87e1-bb5df436689a",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Max neighbors possible: 3\n"
                    ]
                }
            ],
            "source": [
                "targets_list = list(set(map(lambda x: x['SimilarityWith'], targets)))\n",
                "comparison_list = list(set(map(lambda x: x['Name'], comparison)))\n",
                "\n",
                "targets_count = len(targets_list)\n",
                "\n",
                "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
                "tfidf = vectorizer.fit_transform(targets_list)\n",
                "nbrs_model = NearestNeighbors(n_neighbors=targets_count, n_jobs=-1).fit(tfidf)\n",
                "\n",
                "def getNearestN(query, nbrs):\n",
                "  queryTFIDF_ = vectorizer.transform(query)\n",
                "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
                "  return distances, indices\n",
                "\n",
                "dedup_distances, dedup_indices = getNearestN(targets_list, nbrs_model)\n",
                "dedup_matches = []\n",
                "\n",
                "max_dedup_distance = max([max(dist) for dist in dedup_distances])\n",
                "\n",
                "for i, j in enumerate(dedup_indices):\n",
                "  for x in range(targets_count):\n",
                "    temp = [1 - dedup_distances[i][x] / max_dedup_distance, targets_list[j[x]], targets_list[i]]\n",
                "    dedup_matches.append(temp)\n",
                "\n",
                "targets_list = list(targets_list)\n",
                "\n",
                "dedup_matches_df = pd.DataFrame(dedup_matches, columns=['Distance', 'Target name', 'Dataset name'])\n",
                "dedup_matches_df = dedup_matches_df.loc[dedup_matches_df['Distance'] > 0.5]\n",
                "dedup_matches_df = dedup_matches_df \\\n",
                "  .drop_duplicates() \\\n",
                "  .groupby(['Target name']) \\\n",
                "  .size().reset_index(name='counts') \\\n",
                "  .sort_values(by=['counts'], ascending=False) \n",
                "\n",
                "neighbors_count = dedup_matches_df['counts'].iloc[0] + 2\n",
                "print(f'Max neighbors possible: {neighbors_count}')\n",
                "\n",
                "dedup_matches_df.to_csv('tfidf_knn_dedups.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "distances, indices = getNearestN(comparison_list, nbrs_model)\n",
                "comparison_list = list(comparison_list)\n",
                "max_distance = round(max([max(dist) for dist in distances]),2)\n",
                "\n",
                "print(f'Max distance: {max_distance}')\n",
                "\n",
                "matches = []\n",
                "for i,j in enumerate(indices):\n",
                "  for x in range(neighbors_count):\n",
                "    temp = [round(distances[i][x],2), targets_list[j[x]], comparison_list[i]]\n",
                "    matches.append(temp)\n",
                "    \n",
                "print(len(matches))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 245,
            "metadata": {
                "azdata_cell_guid": "4f75fa7e-f71e-46d4-8869-dac3feb7d367",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "34\n"
                    ]
                }
            ],
            "source": [
                "matches_df = pd.DataFrame(matches, columns=['Distance','Target name','Dataset name'])\n",
                "\n",
                "matches_df = matches_df.loc[matches_df['Distance'] < 1.14].loc[matches_df['Distance'] != 1]\n",
                "matches_df = matches_df.drop_duplicates().sort_values(\n",
                "    by=['Target name', 'Distance'], ascending=True)\n",
                "    \n",
                "matches_df.to_csv('tfidf_knn.csv', index=False)\n",
                "print(len(matches_df))"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "67f5144df351139a3446de2ed8df21946e4ce0030a0105ea51bcd18ebd659f47"
        },
        "kernelspec": {
            "display_name": "Python 3.9.5 ('fuzzyvenv': venv)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
