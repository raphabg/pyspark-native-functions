{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Match POC with Apache Spark\n",
    "The objective of this project is to test the execution of native spark functions to perform string similarity analysis, with variated similarity analysis algorithms\n",
    "\n",
    "### Approaches\n",
    "\n",
    "- 1st Approach: Use of native Scala Spark SQL fuzzy match algorithms, crossjoining the input dataset with the target dataset, generating a quatratic computational time\n",
    "- 2nd Approach: Use of Term Frequency, Inverse Document Frequency (TF-IDF) and only then applying native Scala Spark SQL fuzzy match algorithms\n",
    "\n",
    "References:\n",
    "- [Josh Taylor: Fuzzy matching at scale](https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536#:~:text=The%20problem%20with%20Fuzzy%20Matching%20on%20large%20data&text=In%20computer%20science%2C%20this%20is,that%20works%20in%20quadratic%20time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import names\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "sc = SparkContext().getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    'Fuzzy Match POC').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets\n",
    "`targets` is the name list that will be looked up inside `comparison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossJoined dataset size: 319455000\n"
     ]
    }
   ],
   "source": [
    "vogals = ['A', 'E', 'I', 'O', 'U']\n",
    "targets = []\n",
    "comparison = []\n",
    "\n",
    "for i in range(5000):\n",
    "    name = names.get_full_name().upper()\n",
    "    targets.append({'SimilarityWith': name})\n",
    "    comparison.append({'Name': name})\n",
    "\n",
    "    #replace vogals\n",
    "    for vogal in vogals:\n",
    "        for aux_vogal in vogals:\n",
    "            if vogal != aux_vogal:\n",
    "                shuffled_name = name.replace(vogal, aux_vogal)\n",
    "                \n",
    "                if shuffled_name not in list(map(lambda x: x['Name'], comparison)):\n",
    "                    comparison.append({'Name': shuffled_name})\n",
    "\n",
    "targets_df = spark.createDataFrame(targets).alias('t')\n",
    "comparison_df = spark.createDataFrame(comparison).alias('c')\n",
    "\n",
    "print(len(targets))\n",
    "print(len(comparison))\n",
    "\n",
    "print(f\"CrossJoined dataset size: {len(targets) * len(comparison)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional CrossJoin Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev = F.expr('1 - (levenshtein(Name, SimilarityWith) / array_max(array(length(Name), length(SimilarityWith))) )')\n",
    "jaro = F.expr('balogo_jarowinkler(Name, SimilarityWith)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Fuzzy Match count: 81992\n",
      "+--------------+--------------+------------------+\n",
      "|SimilarityWith|          Name|        Similarity|\n",
      "+--------------+--------------+------------------+\n",
      "| FLOYD GAMBILL| FLOYD GAMBILL|               1.0|\n",
      "| FLOYD GAMBILL| FLOYD GEMBILL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GIMBILL|0.9336538461538462|\n",
      "| FLOYD GAMBILL| FLOYD GOMBILL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GUMBILL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GAMBALL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GAMBELL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GAMBOLL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLOYD GAMBULL|0.9461538461538461|\n",
      "| FLOYD GAMBILL| FLAYD GAMBILL|0.9132478632478633|\n",
      "| FLOYD GAMBILL| FLEYD GAMBILL| 0.941025641025641|\n",
      "| FLOYD GAMBILL| FLIYD GAMBILL| 0.941025641025641|\n",
      "| FLOYD GAMBILL| FLUYD GAMBILL| 0.941025641025641|\n",
      "|OZIE HOLSWORTH|OZIE HOLSWORTH|               1.0|\n",
      "|OZIE HOLSWORTH|OZIA HOLSWORTH|0.9476190476190476|\n",
      "|OZIE HOLSWORTH|OZII HOLSWORTH|0.9476190476190476|\n",
      "|OZIE HOLSWORTH|OZIO HOLSWORTH|0.9162087912087913|\n",
      "|OZIE HOLSWORTH|OZIU HOLSWORTH|0.9476190476190476|\n",
      "|OZIE HOLSWORTH|OZAE HOLSWORTH|0.9452380952380952|\n",
      "|OZIE HOLSWORTH|OZEE HOLSWORTH|0.9452380952380952|\n",
      "+--------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = targets_df.crossJoin(comparison_df)\n",
    "df = df.withColumn('Similarity', (lev + jaro) / 2).filter(F.expr('Similarity > 0.8')).cache()\n",
    "\n",
    "print(f\"Filtered Fuzzy Match count: {df.count()}\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks - Conventional Approach\n",
    "\n",
    "|Targets Count|Comparison Count|CrossJoined Dataset Size| Hit Count (< 80%)|Duration\n",
    "|--|--|--|--|--|\n",
    "|5.000|63.891|319.455.000|81.992|32.9s (2m 2.9s)|\n",
    "\n",
    "* Spark seems to take about 1m 30s initialization time independently of the dataset size, at the computer i'm currently running the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency, Inverse Document Frequency (TF-IDF) Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' OZ', 'OZI', 'ZIE', 'IE ', 'E H', ' HO', 'HOL', 'OLS', 'LSW', 'SWO', 'WOR', 'ORT', 'RTH', 'TH ']\n"
     ]
    }
   ],
   "source": [
    "def ngrams(string, n=3):\n",
    "    ngs = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(n) for n in ngs]\n",
    "\n",
    "ngs = ngrams(' OZIE HOLSWORTH ')\n",
    "print(ngs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1966315138f400f62dc1fff91c72ed91dd6df0f36082b426fd0f91ceb8258b5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
