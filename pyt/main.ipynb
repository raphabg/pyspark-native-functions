{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Match POC with Apache Spark\n",
    "The objective of this project is to test the execution of native spark functions to perform string similarity analysis, with variated similarity analysis algorithms\n",
    "\n",
    "### Approaches\n",
    "\n",
    "- 1st Approach: Use of native Scala Spark SQL fuzzy match algorithms, crossjoining the input dataset with the target dataset, generating a quatratic computational time\n",
    "- 2nd Approach: Use of Term Frequency, Inverse Document Frequency (TF-IDF) and only then applying native Scala Spark SQL fuzzy match algorithms\n",
    "\n",
    "References:\n",
    "- [Josh Taylor: Fuzzy matching at scale](https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536#:~:text=The%20problem%20with%20Fuzzy%20Matching%20on%20large%20data&text=In%20computer%20science%2C%20this%20is,that%20works%20in%20quadratic%20time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import names\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "sc = SparkContext().getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    'Fuzzy Match POC').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets\n",
    "`targets` is the name list that will be looked up inside `comparison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "126304\n",
      "CrossJoined dataset size: 1263040000\n"
     ]
    }
   ],
   "source": [
    "shuffle = ['A', 'E', 'I', 'O', 'U', 'H' , 'R', 'P' ,'B', 'J', 'N', 'M', 'G']\n",
    "targets = []\n",
    "comparison = []\n",
    "\n",
    "for i in range(5000):\n",
    "    name = names.get_full_name().upper()\n",
    "    targets.append({'SimilarityWith': name})\n",
    "    comparison.append({'Name': name})\n",
    "\n",
    "    #replace shuffle\n",
    "    for shuffle_char in shuffle:\n",
    "        for shuffle_char_aux in shuffle:\n",
    "            if shuffle_char != shuffle_char_aux:\n",
    "                shuffled_name = name.replace(shuffle_char, shuffle_char_aux)\n",
    "                comparison.append({'Name': shuffled_name})\n",
    "\n",
    "targets = set(targets)\n",
    "comparison = set(comparison)\n",
    "\n",
    "targets_df = spark.createDataFrame(targets).alias('t')\n",
    "comparison_df = spark.createDataFrame(comparison).alias('c')\n",
    "\n",
    "print(len(targets))\n",
    "print(len(comparison))\n",
    "\n",
    "print(f\"CrossJoined dataset size: {len(targets) * len(comparison)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Conventional CrossJoin Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev = F.expr('1 - (levenshtein(Name, SimilarityWith) / array_max(array(length(Name), length(SimilarityWith))) )')\n",
    "jaro = F.expr('balogo_jarowinkler(Name, SimilarityWith)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Fuzzy Match count: 199549\n",
      "+----------------+----------------+------------------+\n",
      "|  SimilarityWith|            Name|        Similarity|\n",
      "+----------------+----------------+------------------+\n",
      "|   GEORGE POWELL|   GEORGE POWELL|               1.0|\n",
      "|   GEORGE POWELL|   GAORGA POWALL|0.8153846153846154|\n",
      "|   GEORGE POWELL|   GIORGI POWILL|0.8153846153846154|\n",
      "|   GEORGE POWELL|   GUORGU POWULL|0.8153846153846154|\n",
      "|   GEORGE POWELL|   GEARGE PAWELL| 0.882051282051282|\n",
      "|   GEORGE POWELL|   GEERGE PEWELL|0.8396270396270396|\n",
      "|   GEORGE POWELL|   GEIRGE PIWELL| 0.882051282051282|\n",
      "|   GEORGE POWELL|   GEURGE PUWELL| 0.882051282051282|\n",
      "|MAURICE ERICKSON|MAURICE ERICKSON|               1.0|\n",
      "|MAURICE ERICKSON|MEURICE ERICKSON|             0.915|\n",
      "|MAURICE ERICKSON|MIURICE ERICKSON|             0.905|\n",
      "|MAURICE ERICKSON|MOURICE ERICKSON|              0.95|\n",
      "|MAURICE ERICKSON|MUURICE ERICKSON|              0.95|\n",
      "|MAURICE ERICKSON|MAURICA ARICKSON|            0.9125|\n",
      "|MAURICE ERICKSON|MAURICI IRICKSON|0.9017857142857143|\n",
      "|MAURICE ERICKSON|MAURICO ORICKSON|0.8910714285714285|\n",
      "|MAURICE ERICKSON|MAURICU URICKSON|            0.9125|\n",
      "|MAURICE ERICKSON|MAURACE ERACKSON|            0.9125|\n",
      "|MAURICE ERICKSON|MAURECE ERECKSON|0.8982142857142857|\n",
      "|MAURICE ERICKSON|MAUROCE EROCKSON|0.8982142857142857|\n",
      "+----------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = targets_df.crossJoin(comparison_df)\n",
    "df = df.withColumn('Similarity', (lev + jaro) / 2).filter(F.expr('Similarity > 0.8')).cache()\n",
    "\n",
    "print(f\"Filtered Fuzzy Match count: {df.count()}\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()\n",
    "pandas_df.to_csv('conventional.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Term Frequency, Inverse Document Frequency (TF-IDF) Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Function that generates list of 3 char length ngrams from full string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=2):\n",
    "    ngs = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(n) for n in ngs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list = list(map(lambda x: x['SimilarityWith'], targets))\n",
    "comparison_list = list(map(lambda x: x['Name'], comparison))\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(targets_list)\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n",
    "\n",
    "distances, indices = getNearestN(comparison_list)\n",
    "comparison_list = list(comparison_list)\n",
    "\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2), targets_list[j[0]], comparison_list[i]]\n",
    "  matches.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126304\n"
     ]
    }
   ],
   "source": [
    "matches_df = pd.DataFrame(matches, columns=['Similarity','Matched name','Origional name'])\n",
    "\n",
    "m = matches_df[\"Similarity\"].max()\n",
    "matches_df[\"Similarity\"] = matches_df[\"Similarity\"].apply(lambda x: 1 - (x / m))\n",
    "#matches_df = matches_df.loc[matches_df['Similarity'] > 0.3]  \n",
    "\n",
    "matches_df = matches_df.sort_values(by=['Similarity'], ascending=False)\n",
    "matches_df.to_csv('tf-idf.csv', index=False)\n",
    "print(len(matches_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "\n",
    "Approach|Targets Count|Comparison Count|CrossJoined Dataset Size| Hit Count | Score Filter | Duration\n",
    "|--|--|--|--|--|--|--|\n",
    "Conventional|10.000|126.304|1.263.040.000|199.549|80% > |~191s (4m 41s)\n",
    "TFIDF|10.000|126.304|-|91.622|0.3 >|15.7s\n",
    "TFIDF|10.000|126.304|-|126.304|N/A|15s\n",
    "TFIDF|5.000|63.635|-|46.411|0.3 >|4.6s\n",
    "Conventional|5.000|63.635|318.175.000|82.011|80% >|~31.2s (2m 1.2s)\n",
    "\n",
    "* Spark seems to take about 1m 30s initialization time independently of the dataset size, at the computer i'm currently running the script"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1966315138f400f62dc1fff91c72ed91dd6df0f36082b426fd0f91ceb8258b5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
